{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "import HTMLParser\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTweet(originalTweet):\n",
    "    htmlParser = HTMLParser.HTMLParser()\n",
    "\n",
    "    tweet = originalTweet\n",
    "    # convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #tweet = htmlParser.unescape(originalTweet);\n",
    "    #tweet = tweet.decode('windows-1252').encode('ascii', 'ignore')\n",
    "    #tweet = tweet.decode('windows-1252')\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #tweet = re.sub(r'[^\\x00-\\xFF]+', r'', tweet)\n",
    "    #tweet = re.sub(r'[^\\x00-\\x7F]+', r'', tweet)\n",
    "    #tweet = tweet.decode('utf-8').strip()\n",
    "    #tweet = tweet.decode('unicode_escape').encode('ascii','ignore')\n",
    "    #tweet = tweet.encode('ascii','ignore')\n",
    "    tweet = ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "    \n",
    "    # remove URLs in tweet\n",
    "    tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "\n",
    "    # remove strings starting with @ in tweet\n",
    "    tweet = re.sub(r'(\\s)@\\w+', r'', tweet)\n",
    "    tweet = re.sub(r'@\\w+', r'', tweet)\n",
    "    \n",
    "    # remove HTML tags from tweet\n",
    "    tweet = re.sub('<[^<]+?>', '', tweet)\n",
    "\n",
    "    # separates words joined with capital words.\n",
    "    # E.g. DisplayIsAweson to Display Is Awesom\n",
    "    #tweet = \" \".join(re.findall('[A-Z][^A-Z]*', tweet));\n",
    "\n",
    "    # remove exclamation and other unnecessary characters\n",
    "    tweet = re.sub(r'[<>!#@$:.,%\\?-]+', r'', tweet)\n",
    "\n",
    "    \n",
    "    \n",
    "    tweet = re.sub(r' a ', r' ', tweet)\n",
    "    tweet = re.sub(r' with ', r' ', tweet)\n",
    "    tweet = re.sub(r' is ', r' ', tweet)\n",
    "    tweet = re.sub(r' to ', r' ', tweet)\n",
    "    tweet = re.sub(r' the ', r' ', tweet)\n",
    "    tweet = re.sub(r' and ', r' ', tweet)\n",
    "    tweet = re.sub(r' of ', r' ', tweet)\n",
    "    tweet = re.sub(r' in ', r' ', tweet)\n",
    "    tweet = re.sub(r' for ', r' ', tweet)\n",
    "    tweet = re.sub(r' all ', r' ', tweet)\n",
    "    tweet = re.sub(r' it ', r' ', tweet)\n",
    "    tweet = re.sub(r' that ', r' ', tweet)\n",
    "    tweet = re.sub(r' for ', r' ', tweet)\n",
    "    tweet = re.sub(r' be ', ' ', tweet)\n",
    "    tweet = re.sub(r' your ', r' ', tweet)\n",
    "    tweet = re.sub(r' our ', r' ', tweet)\n",
    "    tweet = re.sub(r' are ', r' ', tweet)\n",
    "    tweet = re.sub(r' by ', r' ', tweet)\n",
    "    tweet = re.sub(r' this ', r' ', tweet)\n",
    "    tweet = re.sub(r' thi ', r' ', tweet)\n",
    "    tweet = re.sub(r' from ', r' ', tweet)\n",
    "    tweet = re.sub(r' or ', r' ', tweet)\n",
    "    tweet = re.sub(r' website_redact ', r' ', tweet)\n",
    "    tweet = re.sub(r' at ', r' ', tweet)\n",
    "    tweet = re.sub(r' on ', r' ', tweet)\n",
    "    tweet = re.sub(r' href= ', r' ', tweet)\n",
    "    tweet = re.sub(r'\\btarget=_blank\\b', r' ', tweet)\n",
    "    tweet = re.sub(r' also ', r' ', tweet)\n",
    "    tweet = re.sub(r' can ', r' ', tweet)\n",
    "    tweet = re.sub(r' call/text ', r' ', tweet)\n",
    "    tweet = re.sub(r' email ', r' ', tweet)\n",
    "    tweet = re.sub(r' viewingcontact ', r' ', tweet)\n",
    "    tweet = re.sub(r' id ', r' ', tweet)\n",
    "    tweet = re.sub(r' veri ', r' ', tweet)\n",
    "    tweet = re.sub(r' kagglemanagercom ', r' ', tweet)\n",
    "    tweet = re.sub(r' website_redact', r' ', tweet)\n",
    "    # remove extra white spaces\n",
    "    tweet = re.sub(r'\\s+', r' ', tweet)\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = porterStemmer()\n",
    "    stemmedTweet = [stemmer.stem(word) for word in tweet.split(\" \")]\n",
    "    stemmedTweet = \" \".join(stemmedTweet)\n",
    "    \n",
    "    tweet = str(stemmedTweet)\n",
    "    tweet = tweet.replace(\"'\", \"\")\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('C:/Users/shekh/Desktop/rentallisting/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['interest_level'] = df['interest_level'].astype('category')\n",
    "df['interest_level_codes'] = df['interest_level'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "coercing to Unicode: need string or buffer, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b0cb48fc637e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#featuresDF = df[['description', 'features']].apply(lambda x: ' '.join(x), axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdescription_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabel_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'interest_level_codes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         return construct_result(\n\u001b[1;32m    717\u001b[0m             \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36msafe_na_op\u001b[0;34m(lvalues, rvalues)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                     return _algos.arrmap_object(lvalues,\n\u001b[0;32m--> 686\u001b[0;31m                                                 lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\src\\algos_common_helper.pxi\u001b[0m in \u001b[0;36mpandas.algos.arrmap_object (pandas\\algos.c:46681)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\pandas\\core\\ops.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                     return _algos.arrmap_object(lvalues,\n\u001b[0;32m--> 686\u001b[0;31m                                                 lambda x: op(x, rvalues))\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: coercing to Unicode: need string or buffer, list found"
     ]
    }
   ],
   "source": [
    "#featuresDF = df[['description', 'features']].apply(lambda x: ' '.join(x), axis=1)\n",
    "description_column = df['description','features']\n",
    "label_column = df['interest_level_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'description_column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af85929eabb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdescription_col_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabel_col_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'description_column' is not defined"
     ]
    }
   ],
   "source": [
    "description_col_list = description_column.values.tolist()\n",
    "label_col_list = label_column.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean all the tweets\n",
    "i = 0;\n",
    "cleanedDescriptionList = []\n",
    "for description in description_col_list:\n",
    "    #tweet.encode('utf-8').strip()\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #print (i ,),\n",
    "    cleanedDescription = cleanTweet(description).encode('ascii', 'ignore').strip();\n",
    "    cleanedDescriptionList.append(cleanedDescription);\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featureSet = df[['description','display_address']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDescription, testDescription, trainLabels, testLabels = train_test_split(description_column, label_column, \n",
    "                                                                              test_size=0.25, random_state = 40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=0.00125,\n",
    "                             max_df = 0.80,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                            stop_words=u'english',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1,5),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(trainDescription);\n",
    "test_vectors = vectorizer.fit_transform(testDescription);\n",
    "#total_vectors = vectorizer.fit_transform(cleanedDescriptionList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 37014]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4bd7d062b425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmultinomialNBClassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmultinomialNBClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 37014]"
     ]
    }
   ],
   "source": [
    "multinomialNBClassifier = MultinomialNB();\n",
    "multinomialNBClassifier.fit(train_vectors, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = multinomialNBClassifier.predict(test_vectors)\n",
    "predicted_class = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['0', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(testLabels, predicted_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = svmLinearKernelClassifier.score(X_test,actual_class);\n",
    "print score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvScores = cross_val_score(svmLinearKernelClassifier, feature_matrix_df, y_label, cv=10, scoring='f1_micro');\n",
    "print cvScores;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
