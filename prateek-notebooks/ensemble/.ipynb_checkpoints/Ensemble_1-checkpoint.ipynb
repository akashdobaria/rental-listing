{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support as prfs\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "import HTMLParser\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer as porterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanTweet(originalTweet):\n",
    "    htmlParser = HTMLParser.HTMLParser()\n",
    "\n",
    "    tweet = originalTweet\n",
    "    # convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #tweet = htmlParser.unescape(originalTweet);\n",
    "    #tweet = tweet.decode('windows-1252').encode('ascii', 'ignore')\n",
    "    #tweet = tweet.decode('windows-1252')\n",
    "    #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "    #tweet = re.sub(r'[^\\x00-\\xFF]+', r'', tweet)\n",
    "    #tweet = re.sub(r'[^\\x00-\\x7F]+', r'', tweet)\n",
    "    #tweet = tweet.decode('utf-8').strip()\n",
    "    #tweet = tweet.decode('unicode_escape').encode('ascii','ignore')\n",
    "    #tweet = tweet.encode('ascii','ignore')\n",
    "    tweet = ''.join([i if ord(i) < 128 else ' ' for i in tweet])\n",
    "    \n",
    "    # remove URLs in tweet\n",
    "    tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "\n",
    "    # remove strings starting with @ in tweet\n",
    "    tweet = re.sub(r'(\\s)@\\w+', r'', tweet)\n",
    "    tweet = re.sub(r'@\\w+', r'', tweet)\n",
    "    \n",
    "    # remove HTML tags from tweet\n",
    "    tweet = re.sub('<[^<]+?>', '', tweet)\n",
    "\n",
    "    # separates words joined with capital words.\n",
    "    # E.g. DisplayIsAweson to Display Is Awesom\n",
    "    #tweet = \" \".join(re.findall('[A-Z][^A-Z]*', tweet));\n",
    "\n",
    "    # remove exclamation and other unnecessary characters\n",
    "    tweet = re.sub(r'[<>!#@$:.,%\\?-]+', r'', tweet)\n",
    "\n",
    "    \n",
    "    \n",
    "    tweet = re.sub(r' a ', r' ', tweet)\n",
    "    tweet = re.sub(r' with ', r' ', tweet)\n",
    "    tweet = re.sub(r' is ', r' ', tweet)\n",
    "    tweet = re.sub(r' to ', r' ', tweet)\n",
    "    tweet = re.sub(r' the ', r' ', tweet)\n",
    "    tweet = re.sub(r' and ', r' ', tweet)\n",
    "    tweet = re.sub(r' of ', r' ', tweet)\n",
    "    tweet = re.sub(r' in ', r' ', tweet)\n",
    "    tweet = re.sub(r' for ', r' ', tweet)\n",
    "    tweet = re.sub(r' all ', r' ', tweet)\n",
    "    tweet = re.sub(r' it ', r' ', tweet)\n",
    "    tweet = re.sub(r' that ', r' ', tweet)\n",
    "    tweet = re.sub(r' for ', r' ', tweet)\n",
    "    tweet = re.sub(r' be ', ' ', tweet)\n",
    "    tweet = re.sub(r' your ', r' ', tweet)\n",
    "    tweet = re.sub(r' our ', r' ', tweet)\n",
    "    tweet = re.sub(r' are ', r' ', tweet)\n",
    "    tweet = re.sub(r' by ', r' ', tweet)\n",
    "    tweet = re.sub(r' this ', r' ', tweet)\n",
    "    tweet = re.sub(r' thi ', r' ', tweet)\n",
    "    tweet = re.sub(r' from ', r' ', tweet)\n",
    "    tweet = re.sub(r' or ', r' ', tweet)\n",
    "    tweet = re.sub(r' website_redact ', r' ', tweet)\n",
    "    tweet = re.sub(r' at ', r' ', tweet)\n",
    "    tweet = re.sub(r' on ', r' ', tweet)\n",
    "    tweet = re.sub(r' href= ', r' ', tweet)\n",
    "    tweet = re.sub(r'\\btarget=_blank\\b', r' ', tweet)\n",
    "    tweet = re.sub(r' also ', r' ', tweet)\n",
    "    tweet = re.sub(r' can ', r' ', tweet)\n",
    "    tweet = re.sub(r' call/text ', r' ', tweet)\n",
    "    tweet = re.sub(r' email ', r' ', tweet)\n",
    "    tweet = re.sub(r' viewingcontact ', r' ', tweet)\n",
    "    tweet = re.sub(r' id ', r' ', tweet)\n",
    "    tweet = re.sub(r' veri ', r' ', tweet)\n",
    "    tweet = re.sub(r' kagglemanagercom ', r' ', tweet)\n",
    "    tweet = re.sub(r' website_redact', r' ', tweet)\n",
    "    # remove extra white spaces\n",
    "    tweet = re.sub(r'\\s+', r' ', tweet)\n",
    "    \n",
    "    # stemming\n",
    "    stemmer = porterStemmer()\n",
    "    stemmedTweet = [stemmer.stem(word) for word in tweet.split(\" \")]\n",
    "    stemmedTweet = \" \".join(stemmedTweet)\n",
    "    \n",
    "    tweet = str(stemmedTweet)\n",
    "    tweet = tweet.replace(\"'\", \"\")\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('C:/Users/shekh/Desktop/rentallisting/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['interest_level'] = df['interest_level'].astype('category')\n",
    "df['interest_level_codes'] = df['interest_level'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featuresDF = df[['description', 'features']].apply(lambda x: ' '.join(x), axis=1)\n",
    "description_column = df['description']\n",
    "label_column = df['interest_level_codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "description_col_list = description_column.values.tolist()\n",
    "label_col_list = label_column.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # clean all the tweets\n",
    "# i = 0;\n",
    "# cleanedDescriptionList = []\n",
    "# for description in description_col_list:\n",
    "#     #tweet.encode('utf-8').strip()\n",
    "#     #tweet = tweet.decode(\"utf8\").encode('ascii', 'ignore')\n",
    "#     #print (i ,),\n",
    "#     cleanedDescription = cleanTweet(description).encode('ascii', 'ignore').strip();\n",
    "#     cleanedDescriptionList.append(cleanedDescription);\n",
    "    \n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#featureSet = df[['description','display_address']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDescription, testDescription,  , testLabels = train_test_split(description_column, label_column, \n",
    "                                                                              test_size=0.25, random_state = 40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=0.00125,\n",
    "                             max_df = 0.80,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True,\n",
    "                            stop_words=u'english',\n",
    "                            analyzer='word',\n",
    "                            ngram_range=(1,5),lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(trainDescription);\n",
    "test_vectors = vectorizer.fit_transform(testDescription);\n",
    "#total_vectors = vectorizer.fit_transform(cleanedDescriptionList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(37014L,)\n"
     ]
    }
   ],
   "source": [
    "print train_vectors.shape;\n",
    "print trainLabels.shape;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 37014]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4bd7d062b425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmultinomialNBClassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmultinomialNBClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\shekh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 37014]"
     ]
    }
   ],
   "source": [
    "multinomialNBClassifier = MultinomialNB();\n",
    "multinomialNBClassifier.fit(train_vectors, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = multinomialNBClassifier.predict(test_vectors)\n",
    "predicted_class = predicted_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names = ['0', '1', '2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(testLabels, predicted_class, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = svmLinearKernelClassifier.score(X_test,actual_class);\n",
    "print score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvScores = cross_val_score(svmLinearKernelClassifier, feature_matrix_df, y_label, cv=10, scoring='f1_micro');\n",
    "print cvScores;"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
